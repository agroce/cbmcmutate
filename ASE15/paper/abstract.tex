Formal verification has finally advanced to a state where non-experts, including systems software developers, may want to verify the correctness of critical code.  Unfortunately, despite considerable efforts in the area, determining if a ``verification'' actually verifies what the author intends it to is difficult, even for relatively small pieces of code, and even for expert uses of model-checking.  Previous approaches based on vacuity and formal logical structure of a specification are valuable in many cases, but difficult for even experts to understand.  Moreover, while logical vacuity is a critical problem for verification, the working engineer using tools like a bounded model checker is more likely to produce a non-vacuous but over-weak specification.  In this paper we propose a tool framework and methodology to allow both developers and expert users to determine, more precisely, what it is that they have verified.  Our basic approach is based on a novel variation of mutation analysis, a conceptual model of verification based on Popper's notion of falsification as central to scientific discovery, and empirical examination of the ease of SAT/SMT solving in different cases.  We use the popular C/C++ language model-checker CBMC, modified to allow us to determine the ``strength'' of a mutant, and show that our approach is applicable not only to simple, but complete, verification of data structures and sorting routines, but to understanding efforts to verify the Linux kernel Read-Copy-Update mechanism and code from Mozilla's JavaScript engine.

Formal verification has finally advanced to a state where non-experts, including systems software developers, may want to verify the correctness of small but critical modules.  Unfortunately, despite considerable efforts in the area, determining if a ``verification'' actually verifies what the author intends it to is still difficult, even for model checking experts.  Previous approaches from the model checking community are valuable, but difficult to understand and limited in applicability.  Developers using a tool like a bounded model checker need verification coverage in terms of the software they are verifying, rather than in model checking terms.  In this paper we propose a tool framework and methodology to allow both developers and expert users to determine, more precisely, just what it is that they have verified for software systems.  Our basic approach is based on a novel variation of mutation analysis, a conceptual model of verification based on Popper's notion of falsification, and even empirical examination of the ease of SAT/SMT solving in different cases.  We use the popular C/C++ bounded model checker CBMC, modified to allow a user to determine the ``strength'' of a mutant, and show that our approach is applicable not only to simple (but complete, within bounds) verification of data structures and sorting routines, but to understanding efforts to verify the Linux kernel Read-Copy-Update mechanism, code from Mozilla's JavaScript engine, and other real-world examples.
